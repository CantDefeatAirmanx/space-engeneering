services:
    kafka: # Сервис Kafka
        image: confluentinc/cp-kafka:7.9.0 # Образ Kafka от компании Confluent, версия 7.9.0 (современная, с поддержкой KRaft)
        container_name: kafka # Явное имя контейнера, чтобы легче обращаться к нему
        ports:
            - '${kafka__externalPort}:${kafka__externalPort}' # Пробрасываем порт ${kafka__externalPort} наружу — для доступа с хост-машины. Через этот порт будем подключаться клиентами с локального компьютера.

        env_file:
            - ./.env

        environment: # Список переменных окружения для конфигурации Kafka
            # === Основные параметры KRaft (Kafka без Zookeeper) ===
            KAFKA_KRAFT_MODE: 'true' # Включаем работу в режиме KRaft (Kafka Raft Metadata Mode), без ZooKeeper.

            KAFKA_PROCESS_ROLES: controller,broker # Роль текущего процесса: одновременно controller (управляет metadata) и broker (обрабатывает сообщения).

            KAFKA_NODE_ID: 1 # Уникальный идентификатор ноды в кластере Kafka. В кластере должно быть уникальным для каждой ноды.

            KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:${kafka__controllerPort},2@kafka_2:${kafka2__controllerPort},3@kafka_3:${kafka3__controllerPort}'
            # Указываем список участников controller quorum для Raft —
            # в формате "ID@адрес:порт". Кластер из 3 узлов: ID=1,2,3 с соответствующими адресами и портами.
            # Это необходимо для распределённого консенсуса Kafka Metadata.

            # === Listeners (слушатели сети) ===
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:${kafka__internalPort},PLAINTEXT_EXTERNAL://0.0.0.0:${kafka__externalPort},CONTROLLER://kafka:${kafka__controllerPort}
            # Настраиваем, на каких интерфейсах и портах Kafka будет слушать подключения.
            # - PLAINTEXT://0.0.0.0:${kafka__internalPort} — внутренний listener для контейнерной сети Docker.
            # - PLAINTEXT_EXTERNAL://0.0.0.0:${kafka__externalPort} — внешний listener для подключения с локальной машины.
            # - CONTROLLER://kafka:${kafka__controllerPort} — служебный listener для связи контроллера и брокера внутри Kafka.

            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
            # Определяем, какие протоколы безопасности используются для каждого listener.
            # В данном случае все listener'ы используют незашифрованный PLAINTEXT (для локальной разработки).

            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            # Указываем, какой listener используется для связи между брокерами (у нас один broker, но указать нужно).
            # PLAINTEXT — это внутренний listener на ${kafka__internalPort}.

            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            # Указываем, какой listener Kafka будет использовать для связи с controller (служебный трафик Raft).

            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${kafka__internalPort},PLAINTEXT_EXTERNAL://localhost:${kafka__externalPort}
            # Важно! Kafka сообщает клиентам, по каким адресам её можно найти.
            # - Внутри Docker сети Kafka объявляет адрес kafka:${kafka__internalPort}.
            # - Для подключения с хоста Kafka объявляет localhost:${kafka__externalPort}.
            # - Контроллеру Kafka сообщает адрес kafka:${kafka__controllerPort}.

            # === Поведение кластера ===
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
            # Позволяет Kafka автоматически создавать топики при их первом использовании.

            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            # Количество реплик для системного топика offset'ов (кластер из 3 брокеров, поэтому 3).

            KAFKA_LOG_RETENTION_HOURS: 168
            # Хранить сообщения в топиках 168 часов (7 дней).

            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            # Устанавливаем задержку перед начальной балансировкой consumer group в 0 мс (ускоряем старт).

            CLUSTER_ID: 'Mk3OEYBSD34fcwNTJENDM2Qk'
            # Уникальный идентификатор кластера Kafka.

        volumes:
            - kafka_data:/var/lib/kafka/data
            # Подключаем volume для хранения данных Kafka (логи и сообщения).
            # Это позволяет сохранять данные между перезапусками контейнера.

        healthcheck:
            test: ['CMD', 'bash', '-c', 'echo > /dev/tcp/localhost/${kafka__internalPort}']
            interval: 10s
            timeout: 5s
            retries: 10
            start_period: 20s
            # Проверяем, доступен ли порт ${kafka__internalPort} внутри контейнера.
            # Если порт недоступен — Kafka считается неготовой.
            # start_period: 20s — ждём 20 секунд перед началом проверки.

        restart: unless-stopped
        # Автоматически перезапускаем контейнер при сбоях, но не при ручной остановке

        networks:
            - microservices-net
            # Подключаем контейнер к общей сети, в которой живут все сервисы микросервисной архитектуры

    kafka_2: # Второй брокер Kafka в кластере
        image: confluentinc/cp-kafka:7.9.0
        container_name: kafka_2
        ports:
            - '${kafka2__externalPort}:${kafka2__externalPort}'

        env_file:
            - ./.env

        environment:
            # === Основные параметры KRaft ===
            KAFKA_KRAFT_MODE: 'true'
            KAFKA_PROCESS_ROLES: controller,broker
            KAFKA_NODE_ID: 2

            KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:${kafka__controllerPort},2@kafka_2:${kafka2__controllerPort},3@kafka_3:${kafka3__controllerPort}'

            # === Listeners ===
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:${kafka2__internalPort},PLAINTEXT_EXTERNAL://0.0.0.0:${kafka2__externalPort},CONTROLLER://kafka_2:${kafka2__controllerPort}
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka_2:${kafka2__internalPort},PLAINTEXT_EXTERNAL://localhost:${kafka2__externalPort}

            # === Поведение кластера ===
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            KAFKA_LOG_RETENTION_HOURS: 168
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

            CLUSTER_ID: 'Mk3OEYBSD34fcwNTJENDM2Qk'

        volumes:
            - kafka_2_data:/var/lib/kafka/data

        healthcheck:
            test: ['CMD', 'bash', '-c', 'echo > /dev/tcp/localhost/${kafka2__internalPort}']
            interval: 10s
            timeout: 5s
            retries: 10
            start_period: 20s

        restart: unless-stopped

        networks:
            - microservices-net

    kafka_3: # Третий брокер Kafka в кластере
        image: confluentinc/cp-kafka:7.9.0
        container_name: kafka_3
        ports:
            - '${kafka3__externalPort}:${kafka3__externalPort}'

        env_file:
            - ./.env

        environment:
            # === Основные параметры KRaft ===
            KAFKA_KRAFT_MODE: 'true'
            KAFKA_PROCESS_ROLES: controller,broker
            KAFKA_NODE_ID: 3

            KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:${kafka__controllerPort},2@kafka_2:${kafka2__controllerPort},3@kafka_3:${kafka3__controllerPort}'

            # === Listeners ===
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:${kafka3__internalPort},PLAINTEXT_EXTERNAL://0.0.0.0:${kafka3__externalPort},CONTROLLER://kafka_3:${kafka3__controllerPort}
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka_3:${kafka3__internalPort},PLAINTEXT_EXTERNAL://localhost:${kafka3__externalPort}

            # === Поведение кластера ===
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            KAFKA_LOG_RETENTION_HOURS: 168
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

            CLUSTER_ID: 'Mk3OEYBSD34fcwNTJENDM2Qk'

        volumes:
            - kafka_3_data:/var/lib/kafka/data

        healthcheck:
            test: ['CMD', 'bash', '-c', 'echo > /dev/tcp/localhost/${kafka3__internalPort}']
            interval: 10s
            timeout: 5s
            retries: 10
            start_period: 20s

        restart: unless-stopped

        networks:
            - microservices-net

    kafbat-ui: # Веб-интерфейс Kafka UI для управления брокером и топиками.
        env_file:
            - ./.env
        image: ghcr.io/kafbat/kafka-ui:latest
        container_name: kafbat-ui
        ports:
            - '${kafka__uiPort}:8080'
            # Пробрасываем порт веб-интерфейса на хост-машину.

        environment:
            DYNAMIC_CONFIG_ENABLED: 'true'
            KAFKA_CLUSTERS_0_NAME: 'local-cluster'
            KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'kafka:${kafka__internalPort},kafka_2:${kafka2__internalPort},kafka_3:${kafka3__internalPort}'

            KAFKA_CLUSTERS_0_SERDE_0_NAME: 'ProtobufFile'
            KAFKA_CLUSTERS_0_SERDE_0_PROPERTIES_PROTOBUFFILESDIR: '/shared/proto'
            KAFKA_CLUSTERS_0_SERDE_0_PROPERTIES_PROTOBUFMESSAGENAME: 'events.order.v1.OrderEventEnvelope'
            KAFKA_CLUSTERS_0_SERDE_0_PROPERTIES_PROTOBUFMESSAGENAMEBYTOPIC_order: 'events.order.v1.OrderEventEnvelope'
            KAFKA_CLUSTERS_0_SERDE_0_PROPERTIES_PROTOBUFMESSAGENAMEBYTOPIC_assembly: 'events.assembly.v1.ShipAssemblyEventEnvelope'

        depends_on:
            kafka:
                condition: service_healthy
            kafka_2:
                condition: service_healthy
            kafka_3:
                condition: service_healthy
            # Гарантируем, что Kafbat UI стартует только после того, как все брокеры кластера станут healthy.

        healthcheck:
            test: ['CMD', 'curl', '-f', 'http://localhost:8080/actuator/health']
            interval: 10s
            timeout: 5s
            retries: 10
            start_period: 20s
            # Проверяем состояние UI по HTTP endpoint /actuator/health.
            # UI будет считаться healthy только после успешного ответа от сервера.

        volumes:
            - ../../shared/proto:/shared/proto:ro

        restart: unless-stopped
        # Автоматически перезапускаем контейнер при сбоях, но не при ручной остановке

        networks:
            - microservices-net
            # Подключаем контейнер к общей сети, в которой живут все сервисы микросервисной архитектуры

volumes: # Раздел с определением томов
    kafka_data: # Именованный том для хранения данных первого брокера Kafka
    kafka_2_data: # Именованный том для хранения данных второго брокера Kafka
    kafka_3_data: # Именованный том для хранения данных третьего брокера Kafka
    # Docker сам управляет этими хранилищами, данные сохраняются между перезапусками контейнеров.

networks:
    microservices-net:
        name: microservices-net
        external: false
        driver: bridge
